{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "# This is a work in progress notebook for testing functions before submitting the final project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "Overall ETL Process:\n",
    " 1. [DONE] Automatically Drop & create staging & fact/dimension tables (including creating appropriate roles & attaching policies)\n",
    " 2. [DONE] Connect to Udacity S3 and pull files into Redshift staging (using copy)\n",
    " 3. [In Progress] Copy data into analytics tables; perform entirely in SQL, no python processing.\n",
    " - Check: may need to change datatypes of staging table to be correct up front, OR, see if the insert will auto enforce the new data type.\n",
    " 4. Bring you infra as code into the etl script so the entire project runs end to end\n",
    " 5. (Optional) create data cubes)\n",
    " \n",
    " Comment: do everything in **us-west-2 (Oregan)** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'s3://udacity-dend/log_data'\n"
     ]
    }
   ],
   "source": [
    "# Connect to S3 and explore the file source data\n",
    "from time import time\n",
    "import configparser\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import sql_queries\n",
    "import create_dwh\n",
    "import delete_dwh\n",
    "import create_tables\n",
    "import etl\n",
    "from smart_open import smart_open\n",
    "\n",
    "\n",
    "config = configparser.ConfigParser()\n",
    "config.read_file(open('dwh.cfg'))\n",
    "KEY=config.get('AWS','key')\n",
    "SECRET= config.get('AWS','secret')\n",
    "LOG_DATA= config.get('S3', 'log_data') \n",
    "LOG_JSONPATH= config.get('S3', 'log_jsonpath')\n",
    "SONG_DATA= config.get('S3', 'song_data')\n",
    "print(LOG_DATA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.1 Creating a new IAM Role\n",
      "An error occurred (EntityAlreadyExists) when calling the CreateRole operation: Role with name dwhRole already exists.\n",
      "Attaching S3 Policy\n",
      "Policy Attached\n",
      "Attaching Redshift Policy\n",
      "Policy Attached\n",
      "1.3 Get the IAM role ARN\n",
      "arn:aws:iam::230036167675:role/dwhRole\n",
      "Cluster Created\n"
     ]
    }
   ],
   "source": [
    "# Create Redshift Cluster\n",
    "%run -i create_dwh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dwhcluster.ctm8gofjtwwi.us-west-2.redshift.amazonaws.com\n",
      "Connected to: dwh\n",
      "Now executing: CREATE TABLE IF NOT EXISTS staging_events (\n",
      "    artist text,\n",
      "    auth text,\n",
      "    firstName text,\n",
      "    gender text,\n",
      "    itemInSession text,\n",
      "    lastName text,\n",
      "    length numeric,\n",
      "    level text,\n",
      "    location text,\n",
      "    method text,\n",
      "    page text,\n",
      "    registration text,\n",
      "    sessionId integer,\n",
      "    song text,\n",
      "    status text,\n",
      "    ts timestamp,\n",
      "    userAgent text,\n",
      "    userID int\n",
      ")\n",
      ";\n",
      "Now executing: CREATE TABLE IF NOT EXISTS staging_songs (\n",
      "    num_songs text,\n",
      "    artist_id text,\n",
      "    latitude numeric,\n",
      "    longitude numeric,\n",
      "    location text,\n",
      "    name text,\n",
      "    song_id text,\n",
      "    title text,\n",
      "    duration numeric,\n",
      "    year integer\n",
      ")\n",
      ";\n",
      "Now executing: \n",
      "    CREATE TABLE IF NOT EXISTS users (\n",
      "    user_id int,\n",
      "    first_name varchar,\n",
      "    last_name varchar,\n",
      "    gender varchar, \n",
      "    level varchar\n",
      "    )\n",
      ";\n",
      "Now executing: \n",
      "    CREATE TABLE IF NOT EXISTS songs (\n",
      "    song_id varchar,\n",
      "    title varchar,\n",
      "    artist_id text,\n",
      "    year int,\n",
      "    duration numeric\n",
      "    )\n",
      ";\n",
      "Now executing: \n",
      "    CREATE TABLE IF NOT EXISTS artists (\n",
      "    artist_id text,\n",
      "    name varchar,\n",
      "    location varchar,\n",
      "    latitude numeric,\n",
      "    longitude numeric\n",
      "    )\n",
      ";\n",
      "Now executing: \n",
      "    CREATE TABLE IF NOT EXISTS time (\n",
      "    start_time timestamp,\n",
      "    hour int,\n",
      "    day int,\n",
      "    week int, \n",
      "    month int, \n",
      "    year int,\n",
      "    weekday int\n",
      "    )\n",
      ";\n",
      "Now executing: \n",
      "    CREATE TABLE IF NOT EXISTS songplays (\n",
      "    songplay_id int IDENTITY(0,1), \n",
      "    start_time time, \n",
      "    user_id int,\n",
      "    level varchar,\n",
      "    song_id varchar,\n",
      "    artist_id text,\n",
      "    session_id int,\n",
      "    location varchar,\n",
      "    user_agent varchar,\n",
      "    PRIMARY KEY(songplay_id)\n",
      "    )\n",
      ";\n"
     ]
    }
   ],
   "source": [
    "# Create Tables\n",
    "%run -i create_tables\n",
    "# first time error: string indices must be integer, then it works after..\n",
    "# fails until the cluster exists, actually need to put a 'wait'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected to: dwh\n",
      "Copy Query Completed:copy staging_events from 's3://udacity-dend/log_data'\n",
      "                            credentials 'aws_iam_role=arn:aws:iam::230036167675:role/dwhRole'\n",
      "                             region 'us-west-2'\n",
      "                             timeformat as 'epochmillisecs'\n",
      "                             truncatecolumns blanksasnull emptyasnull\n",
      "                             json 's3://udacity-dend/log_json_path.json'  \n",
      ";\n",
      "Copy Query Completed:copy staging_songs from 's3://udacity-dend/song_data'\n",
      "                            credentials 'aws_iam_role=arn:aws:iam::230036167675:role/dwhRole'\n",
      "                            format as json 'auto' \n",
      "                            region 'us-west-2'\n",
      ";\n",
      "Insert Query Completed:\n",
      "INSERT INTO songs (song_id, title, artist_id, year, duration) \n",
      "SELECT \n",
      "    song_id, \n",
      "    title, \n",
      "    artist_id, \n",
      "    year, \n",
      "    duration as numeric\n",
      "FROM staging_songs\n",
      ";\n",
      "Insert Query Completed:\n",
      "INSERT INTO artists (artist_id, name, location, latitude, longitude) \n",
      "SELECT\n",
      "    artist_id,\n",
      "    name,\n",
      "    location,\n",
      "    latitude,\n",
      "    longitude\n",
      "FROM staging_songs\n",
      ";\n",
      "Insert Query Completed:\n",
      "INSERT INTO time (start_time, hour, day, week, month, year, weekday) \n",
      "SELECT \n",
      "    ts as start_time,\n",
      "    extract(hour from ts) as hour,\n",
      "    extract(d from ts) as day, --day of month from 1 to 30/31\n",
      "    extract(w from ts) as week,\n",
      "    extract(mon from ts) as month, \n",
      "    extract(yr from ts) as year,\n",
      "    extract(weekday from ts) as weekday -- day of week from 0 to 6\n",
      "FROM staging_events\n",
      "WHERE page = 'NextSong' \n",
      ";\n",
      "Insert Query Completed:\n",
      "INSERT INTO users (user_id, first_name, last_name, gender, level) \n",
      "SELECT DISTINCT \n",
      "    userID as user_id,\n",
      "    firstName as first_name,\n",
      "    lastName as last_name,\n",
      "    gender,\n",
      "    level\n",
      "FROM staging_events\n",
      "WHERE page = 'NextSong'\n",
      "GROUP BY userID, firstName, lastName, gender, level, ts\n",
      "ORDER BY user_id, ts DESC\n",
      ";\n",
      "Insert Query Completed:\n",
      "INSERT INTO songplays (start_time, user_id, level, song_id, artist_id, session_id, location, user_agent)\n",
      "SELECT   events.ts,\n",
      "         events.userID,\n",
      "         events.level,\n",
      "         songs.song_id,\n",
      "         songs.artist_id,\n",
      "         events.sessionId,\n",
      "         events.location,\n",
      "         events.userAgent\n",
      "FROM staging_events AS events\n",
      "JOIN staging_songs AS songs\n",
      "     ON (events.artist = songs.name)\n",
      "     AND (events.song = songs.title)\n",
      "     AND (events.length = songs.duration)\n",
      "     WHERE events.page = 'NextSong'\n",
      ";\n"
     ]
    }
   ],
   "source": [
    "# Copy from S3 to staging & execute one insert statement\n",
    "%run -i etl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster deleted\n"
     ]
    }
   ],
   "source": [
    "# Delete cluster\n",
    "%run -i delete_dwh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
